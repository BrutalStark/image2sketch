{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRy1MPDuNRvp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import functools\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import torch.utils.data as data\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "aObDxO6iRA38",
    "outputId": "932c2fc7-40a7-4080-957a-b7173d61b8fa"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    # options for model train\n",
    "    'mode': 'test',\n",
    "    'lr': 0.0002,\n",
    "    'lambdaG': 1,\n",
    "    'lambdaA': 10,\n",
    "    'epoch_count': 1,\n",
    "    'niter': 100, \n",
    "    'niter_decay': 50,\n",
    "    'model_save_path': '/content/drive/My Drive/image2sketch/out/model',\n",
    "    \n",
    "    'data_path': Path('/content/drive/My Drive/image2sketch/all-in-one'),\n",
    "    'n_gt': 5,\n",
    "    'width': 5,\n",
    "    'img_size': 256,\n",
    "    \n",
    "    'batch_size': 16,\n",
    "    'is_shuffle': False,\n",
    "    \n",
    "    'save_freq': 2,\n",
    "    'log_freq': 20,\n",
    "    'img_log_path': '/content/drive/My Drive/image2sketch/out/img',\n",
    "    'device': 'cpu',\n",
    "    \n",
    "    # options for model test\n",
    "    'test_image': 'test.jpg',\n",
    "    'test_output': 'test_result.jpg',\n",
    "    'model_load_path': './output/model',\n",
    "    'model_load_epoch': 120,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0a8VEPXNRvv"
   },
   "source": [
    "# networks\n",
    "## unet generator\n",
    "### unet module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CPIWmjhWNRvw",
    "outputId": "2c0628ee-bbd4-497b-c0ea-e3be6665a6d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512, 4, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class unetModule(nn.Module):\n",
    "    def __init__(self, input_nc, inner_nc, output_nc=None, sub_module=None, is_outest=False):\n",
    "        super(unetModule, self).__init__()\n",
    "        self.is_outest = is_outest\n",
    "        \n",
    "        conv = nn.Conv2d(input_nc, inner_nc, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        down_norm = nn.BatchNorm2d(inner_nc)\n",
    "        up_norm = nn.BatchNorm2d(input_nc)\n",
    "        \n",
    "        down_relu = nn.LeakyReLU(0.2, True)\n",
    "        up_relu = nn.ReLU(True)\n",
    "        tanh = nn.Tanh()\n",
    "        \n",
    "        if is_outest:\n",
    "            assert(output_nc != None)\n",
    "            \n",
    "            convT = nn.ConvTranspose2d(inner_nc * 2, output_nc, kernel_size=4, stride=2, padding=1)\n",
    "            up = [convT] + [tanh]\n",
    "            \n",
    "            down = [conv] + [down_relu]\n",
    "        elif sub_module:\n",
    "            convT = nn.ConvTranspose2d(inner_nc * 2, input_nc, kernel_size=4, stride=2, padding=1)\n",
    "            up = [convT] + [up_norm] + [up_relu]\n",
    "            \n",
    "            down = [conv] + [down_norm] + [down_relu]\n",
    "        else:\n",
    "            convT = nn.ConvTranspose2d(inner_nc, input_nc, kernel_size=4, stride=2, padding=1)\n",
    "            up = [convT] + [up_norm] + [up_relu]\n",
    "            \n",
    "            down = [conv] + [down_relu]\n",
    "            \n",
    "        if sub_module:\n",
    "            model = down + [sub_module] + up\n",
    "        else:\n",
    "            model = down + up\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.is_outest:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat((x, self.model(x)), 1)\n",
    "\n",
    "# inner_test = torch.ones(16, 256, 4, 4)\n",
    "# unetModule_test = unetModule(256, 512)\n",
    "# rslt = unetModule_test(inner_test)\n",
    "# rslt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNyygDRANRvz"
   },
   "source": [
    "### build unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vYIIdAXSNRv0",
    "outputId": "2afd5a13-a802-4344-a6a4-f407de4dad21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class unetG(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_wrapper, first_nc=64):\n",
    "        super(unetG, self).__init__()\n",
    "        \n",
    "        unet_submodule = unetModule(first_nc * 2**3, first_nc * 2**3)\n",
    "        for _ in range(num_wrapper-4):\n",
    "            unet_submodule = unetModule(first_nc * 2**3, first_nc * 2**3, sub_module=unet_submodule)\n",
    "        \n",
    "        unet_submodule = unetModule(first_nc * 2**2, first_nc * 2**3, sub_module=unet_submodule)\n",
    "        unet_submodule = unetModule(first_nc * 2**1, first_nc * 2**2, sub_module=unet_submodule)\n",
    "        unet_submodule = unetModule(first_nc, first_nc * 2**1, sub_module=unet_submodule)\n",
    "        unet_submodule = unetModule(input_nc, first_nc, sub_module=unet_submodule, \n",
    "                                    output_nc=output_nc, is_outest=True)\n",
    "        \n",
    "        self.model = unet_submodule\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "x_test = torch.ones(16, 3, 256, 256)\n",
    "unetG_test = unetG(3, 1, num_wrapper=7)\n",
    "rslt = unetG_test(x_test)\n",
    "print(rslt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c95wvCDENRv3"
   },
   "source": [
    "## patchGAN discriminator\n",
    "### build net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y4rgruKUNRv4",
    "outputId": "caea48e8-a2c7-4c99-b475-82648b593763"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 62, 62])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class patchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, first_nc=64, num_layers=3):\n",
    "        super(patchDiscriminator, self).__init__()\n",
    "        \n",
    "        model = [nn.Conv2d(input_nc, first_nc, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True)]\n",
    "        for i_layer in range(num_layers-1):\n",
    "            conv = nn.Conv2d(first_nc * 2**i_layer, first_nc * 2**(i_layer+1), kernel_size=4, stride=2, padding=1)\n",
    "            batch_norm = nn.BatchNorm2d(first_nc * 2**(i_layer+1))\n",
    "            relu = nn.LeakyReLU(0.2, True)\n",
    "            model.extend([conv]+[batch_norm]+[relu])\n",
    "        \n",
    "        conv = nn.Conv2d(first_nc * 4, first_nc * 8, kernel_size=4, stride=1, padding=1)\n",
    "        batch_norm = nn.BatchNorm2d(first_nc * 8)\n",
    "        relu = nn.LeakyReLU(0.2, True)\n",
    "        model.extend([conv]+[batch_norm]+[relu])\n",
    "        \n",
    "        conv = nn.Conv2d(first_nc * 8, 1, kernel_size=4, stride=1, padding=1)\n",
    "        model.append(conv)\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "x_test = torch.ones(16, 3, 512, 512)\n",
    "test_patchDiscriminator = patchDiscriminator(3)\n",
    "rslt = test_patchDiscriminator(x_test)\n",
    "rslt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITJouIYCNRv6"
   },
   "source": [
    "## network utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9ro_gGFNRv7"
   },
   "outputs": [],
   "source": [
    "def init_weight(network):\n",
    "    def weights_init_normal(m):\n",
    "        classname = m.__class__.__name__\n",
    "        # print(classname)\n",
    "        if classname.find('Conv') != -1:\n",
    "            init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('Linear') != -1:\n",
    "            init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "    network.apply(weights_init_normal)\n",
    "    \n",
    "# test_init = init_weight(unetG_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiOnKoS7NRv9"
   },
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-f7IrkGuNRv-",
    "outputId": "a27dac79-4ddb-4c58-a330-4bced3b6dad9"
   },
   "outputs": [],
   "source": [
    "class baseGANLoss:\n",
    "    def __init__(self, gan_type='BCE', device='cuda'):\n",
    "        self.device = device\n",
    "        self.loss = nn.BCEWithLogitsLoss().to(device)\n",
    "    \n",
    "    def __call__(self, prediction, is_real):\n",
    "        if is_real:\n",
    "            target_tensor = torch.ones(prediction.shape).to(self.device)\n",
    "        else:\n",
    "            target_tensor = torch.zeros(prediction.shape).to(self.device)\n",
    "        return self.loss(prediction, target_tensor)\n",
    "\n",
    "# test_baseGANLoss = baseGANLoss()\n",
    "# test_baseGANLoss(torch.tensor([1, 0.1, 0.5]).to('cuda'), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpqNIWJRNRwB"
   },
   "source": [
    "# model\n",
    "## pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0ewvas-NRwC"
   },
   "outputs": [],
   "source": [
    "class pix2pix:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        \n",
    "        # networks\n",
    "        self.netG = unetG(3, 1, num_wrapper=7).to(opt['device'])\n",
    "        self.netD = patchDiscriminator(4).to(opt['device'])\n",
    "        init_weight(self.netG)\n",
    "        init_weight(self.netD)\n",
    "                \n",
    "        if opt['mode'] is 'train':\n",
    "            # criterion\n",
    "            self.criterionGAN = baseGANLoss(device=opt['device'])\n",
    "            \n",
    "            # optimizer\n",
    "            self.optimizer_G = optim.Adam(self.netG.parameters(), lr=opt['lr'], betas=(0.5, 0.999))\n",
    "            self.optimizer_D = optim.Adam(self.netD.parameters(), lr=opt['lr'], betas=(0.5, 0.999))\n",
    "            \n",
    "            # lr scheduler \n",
    "            self.lr_scheduler_G = self.get_scheduler(self.optimizer_G)\n",
    "            self.lr_scheduler_D = self.get_scheduler(self.optimizer_D)\n",
    "        \n",
    "        if opt['mode'] is 'test':\n",
    "            self.netG.load_state_dict(torch.load( opt['model_load_path']+ ('/G_net_%d.pth' % opt['model_load_epoch'])\n",
    "                                                 ,map_location=torch.device(opt['device'])  ) )\n",
    "            \n",
    "    def set_inputs(self, inputs):\n",
    "        self.A_real = inputs['A']\n",
    "        self.B_real = inputs['B']\n",
    "    \n",
    "    def forward(self):\n",
    "        self.B_fake = self.netG(self.A_real)\n",
    "        \n",
    "    def backward_D(self):\n",
    "        # fake images\n",
    "        input_D_fake = torch.cat((self.A_real, self.B_fake), 1).detach()\n",
    "        pred_fake = self.netD(input_D_fake)\n",
    "        self.loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "        \n",
    "        # a set of real images\n",
    "        n_real = self.B_real.shape[1]\n",
    "        loss_D_real_n = torch.zeros(n_real)\n",
    "        for i_real in range(n_real):\n",
    "            B_real_i = self.B_real[:, i_real, :, :].unsqueeze(1)\n",
    "            input_D_real = torch.cat((self.A_real, B_real_i), 1).detach()\n",
    "            pred_real = self.netD(input_D_real)\n",
    "            loss_D_real_n[i_real] = self.criterionGAN(pred_real, True)\n",
    "        self.loss_D_real = torch.mean(loss_D_real_n).to(self.opt['device'])\n",
    "        \n",
    "        # combine loss\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        \n",
    "        # backward\n",
    "        self.loss_D.backward()\n",
    "    \n",
    "    def backward_G(self):\n",
    "        # First, G(A) should fake the discriminator\n",
    "        input_D_fake = torch.cat((self.A_real, self.B_fake), 1)\n",
    "        pred_fake = self.netD(input_D_fake)\n",
    "        loss_G = self.criterionGAN(pred_fake, True)\n",
    "        \n",
    "        # Second, G(A) = B\n",
    "        n_real = self.B_real.shape[1]\n",
    "        \n",
    "        self.B_fake.expand([-1, n_real, -1, -1])\n",
    "        loss_G_L1 = torch.abs(self.B_real - self.B_fake)\n",
    "        loss_G_L1 = loss_G_L1.view(-1, n_real, loss_G_L1.shape[2]*loss_G_L1.shape[3])\n",
    "        loss_G_L1 = torch.mean(loss_G_L1, 2)\n",
    "        \n",
    "        min_loss_G_L1, min_index = (torch.min(loss_G_L1, 1))\n",
    "        self.min_index = min_index\n",
    "        \n",
    "        # Combine loss\n",
    "        self.loss_G = loss_G * self.opt['lambdaG'] + torch.mean(min_loss_G_L1) * self.opt['lambdaA']\n",
    "        \n",
    "        # backward\n",
    "        self.loss_G.backward()\n",
    "    \n",
    "    def update(self):\n",
    "        def set_is_require_grad(net, is_require):\n",
    "            for param in net.parameters():\n",
    "                param.require_grad = is_require\n",
    "                \n",
    "        # generate fake B\n",
    "        self.forward()\n",
    "        \n",
    "        # update discriminator D\n",
    "        set_is_require_grad(self.netD, is_require=True)\n",
    "        self.optimizer_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.optimizer_D.step()\n",
    "        \n",
    "        # update generator G\n",
    "        set_is_require_grad(self.netD, is_require=False)\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "    \n",
    "    def get_scheduler(self, optimizer):\n",
    "        def lambda_rule(epoch, opt=self.opt):\n",
    "            lr_l = 1.0 - max(0, epoch + 1 + opt['epoch_count'] - opt['niter']) / float(opt['niter_decay'] + 1)\n",
    "            return lr_l\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "        return scheduler\n",
    "\n",
    "    def update_lr(self):\n",
    "        self.lr_scheduler_G.step()\n",
    "        self.lr_scheduler_D.step()\n",
    "            \n",
    "    def save(self, epoch):\n",
    "        def save_network(net, net_type, epoch):\n",
    "            filename = Path(self.opt['model_save_path']) / ('%s_net_%d.pth' % (net_type, epoch))\n",
    "            torch.save(net.state_dict(), filename)\n",
    "        save_network(self.netD, 'D', epoch)\n",
    "        save_network(self.netG, 'G', epoch)\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return {'loss_G': self.loss_G.item(), 'loss_D': self.loss_D.item()}\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return {'G': self.optimizer_G.param_groups[0]['lr'], \n",
    "                'D': self.optimizer_D.param_groups[0]['lr']}\n",
    "    \n",
    "    def get_B_fake(self):\n",
    "        return self.B_fake.detach()[0][0]\n",
    "    \n",
    "    def get_B_best_real(self):\n",
    "        return self.B_real.detach()[0][self.min_index[0]]\n",
    "\n",
    "# opt = {\n",
    "#     'mode': 'train',\n",
    "#     'lr': 0.0002,\n",
    "#     'lambdaG': 1,\n",
    "#     'lambdaA': 10,\n",
    "#     'epoch_count': 1,\n",
    "#     'niter': 100, \n",
    "#     'niter_decay': 100,\n",
    "#     'model_save_path': '/content/drive/My Drive/image2sketch/out/model',\n",
    "#     'device': 'cuda'\n",
    "# }\n",
    "\n",
    "# test_A_real = torch.rand([4, 3, 256, 256], dtype=torch.float32).to(opt['device'])\n",
    "# test_B_real = torch.rand([4, 4, 256, 256], dtype=torch.float32).to(opt['device'])\n",
    "# test_inputs= {}\n",
    "# test_inputs['A'] = test_A_real\n",
    "# test_inputs['B'] = test_B_real\n",
    "\n",
    "# test_pix2pix = pix2pix(opt)\n",
    "# test_pix2pix.set_inputs(test_inputs)\n",
    "# test_pix2pix.update()\n",
    "# test_pix2pix.save(-1)\n",
    "# test_pix2pix.update_lr()\n",
    "\n",
    "# B_fake = test_pix2pix.get_B_fake()\n",
    "# B_best_real = test_pix2pix.get_B_best_real()\n",
    "\n",
    "# B_fake_img = Image.fromarray((B_fake.cpu().numpy() + 1) * 255 / 2)\n",
    "# B_best_real_img = Image.fromarray((B_best_real.cpu().numpy() + 1) * 255 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8RB94OmNRwE"
   },
   "source": [
    "# data\n",
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGVmZbeTNRwF"
   },
   "outputs": [],
   "source": [
    "class one2pairDataset(data.Dataset):\n",
    "    def __init__(self, opt, dataset_type):\n",
    "        super(one2pairDataset, self).__init__()\n",
    "        self.opt = opt\n",
    "        \n",
    "        file_path = opt['data_path'] / 'list' / (dataset_type + '.txt')\n",
    "        with open(file_path) as f:\n",
    "            content = f.readlines()\n",
    "        self.file_names = sorted([x.strip() for x in content])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        num_groud_truth = self.opt['n_gt']\n",
    "        file_id = self.file_names[index]\n",
    "        img_size = self.opt['img_size']\n",
    "\n",
    "        path_img = self.opt['data_path'] / 'image' / (file_id + '.jpg')\n",
    "        img = Image.open(path_img)\n",
    "        img = img.resize((img_size, img_size), Image.BICUBIC)\n",
    "        img = transforms.ToTensor()(img)\n",
    "        img = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(img)\n",
    "        \n",
    "        sketches = num_groud_truth * [None]\n",
    "        for i_gt in range(num_groud_truth):\n",
    "            path_sketch = self.opt['data_path'] / 'sketch-rendered' \\\n",
    "                            / ('width-%d' % self.opt['width']) / ('%s_%02d.png' % (file_id, i_gt + 1))\n",
    "            sketch = Image.open(path_sketch)\n",
    "            sketch = sketch.resize((img_size, img_size), Image.BICUBIC)\n",
    "            sketch = transforms.ToTensor()(sketch)\n",
    "            sketch = transforms.Normalize((0.5), (0.5))(sketch)\n",
    "            sketches[i_gt] = sketch\n",
    "        sketches = torch.cat(sketches, 0)\n",
    "        \n",
    "        return {'A': img, 'B': sketches}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "# opt = {\n",
    "#     'mode': 'train',\n",
    "#     'lr': 0.0002,\n",
    "#     'lambdaG': 1,\n",
    "#     'lambdaA': 10,\n",
    "#     'epoch_count': 1,\n",
    "#     'niter': 100, \n",
    "#     'niter_decay': 100,\n",
    "#     'model_save_path': '/content/drive/My Drive/image2sketch/out/model/',\n",
    "    \n",
    "#     'data_path': Path('/content/drive/My Drive/image2sketch/all-in-one'),\n",
    "#     'mode': 'train',\n",
    "#     'n_gt': 5,\n",
    "#     'width': 5,\n",
    "#     'img_size': 256,\n",
    "# }\n",
    "# test_dataset_type = 'train'\n",
    "\n",
    "# test_one2pairDataset = one2pairDataset(opt, dataset_type=test_dataset_type)\n",
    "# img_paired = test_one2pairDataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WBkjJ2YoNRwI"
   },
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYylV20rNRwI"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(opt, dataset_type=['train', 'val', 'test']):\n",
    "    dataloaders = {}\n",
    "    for types in dataset_type:\n",
    "        dataset = one2pairDataset(opt, dataset_type=types)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                                 batch_size=opt['batch_size'],\n",
    "                                                 shuffle=opt['is_shuffle'])\n",
    "        dataloaders[types] = dataloader\n",
    "    return dataloaders\n",
    "\n",
    "# opt = {\n",
    "#     'mode': 'train',\n",
    "#     'lr': 0.0002,\n",
    "#     'lambdaG': 1,\n",
    "#     'lambdaA': 10,\n",
    "#     'epoch_count': 1,\n",
    "#     'niter': 100, \n",
    "#     'niter_decay': 100,\n",
    "#     'model_save_path': '/content/drive/My Drive/image2sketch/out/model/l',\n",
    "    \n",
    "#     'data_path': Path('/content/drive/My Drive/image2sketch/all-in-one'),\n",
    "#     'mode': 'train',\n",
    "#     'n_gt': 5,\n",
    "#     'width': 5,\n",
    "#     'img_size': 256,\n",
    "    \n",
    "#     'batch_size': 1,\n",
    "#     'is_shuffle': False,\n",
    "    \n",
    "# }\n",
    "        \n",
    "# test_dataloaders = get_dataloader(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGr761G8NRwK"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zp3-B8-mNRwK",
    "outputId": "fd828561-6c3a-4a1d-9dd4-19cbf2005cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is now in test mode, please check opt.\n"
     ]
    }
   ],
   "source": [
    "if opt['mode'] is 'train':\n",
    "    dataloaders = get_dataloader(opt)\n",
    "    model = pix2pix(opt)\n",
    "    \n",
    "    lrs = []\n",
    "    for epoch in range(0, 1 + opt['niter'] + opt['niter_decay']):\n",
    "        epoch_time = 0\n",
    "        epoch_cost_G = 0\n",
    "        epoch_cost_D = 0\n",
    "        for i, data in enumerate(dataloaders['test']):\n",
    "            batch_time_start = time.time()\n",
    "            \n",
    "            # put data to gpu\n",
    "            data['A'] = data['A'].to(opt['device'])\n",
    "            data['B'] = data['B'].to(opt['device'])\n",
    "            \n",
    "            model.set_inputs(data)\n",
    "            model.update()\n",
    "            batch_loss = model.get_loss()\n",
    "            \n",
    "            batch_time_end = time.time()\n",
    "            \n",
    "            if i % opt['log_freq'] is 0:\n",
    "                print('Epoch %d, batch %d. loss of G: %3f; loss of D: %3f;' \\\n",
    "                      % (epoch, i, batch_loss['loss_G'], batch_loss['loss_D']))\n",
    "            \n",
    "            epoch_time += (batch_time_end - batch_time_start)\n",
    "            epoch_cost_G += batch_loss['loss_G']\n",
    "            epoch_cost_D += batch_loss['loss_D']\n",
    "            \n",
    "        if epoch % opt['save_freq'] is 0:\n",
    "            model.save(epoch)\n",
    "\n",
    "            img_save_path = Path(opt['img_log_path'])\n",
    "            B_fake_img = Image.fromarray((model.get_B_fake().cpu().numpy() + 1) * 255 / 2 ).convert('RGB')\\\n",
    "                            .save(img_save_path / ('%d_fake.png' % epoch))\n",
    "            B_real_best = Image.fromarray((model.get_B_best_real().cpu().numpy() + 1) * 255 / 2 ).convert('RGB')\\\n",
    "                            .save(img_save_path / ('%d_true.png' % epoch))\n",
    "            \n",
    "        model.update_lr()\n",
    "        lrs.append(model.get_lr()['G'])\n",
    "        \n",
    "        \n",
    "        print('Epoch %d finished. cost time %.3f; mean loss of G %.3f; mean loss of D %.3f.' \\\n",
    "              % (epoch, epoch_time, epoch_cost_G / (i + 1), epoch_cost_D / (i+1)))\n",
    "        \n",
    "else:\n",
    "    print('It is now in test mode, please check opt.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt['mode'] is 'test':\n",
    "    # get test image\n",
    "    test_img_path = opt['test_image']\n",
    "    test_img = Image.open(test_img_path)\n",
    "    test_img = test_img.resize((1024, 1024), Image.BICUBIC)\n",
    "    test_img = transforms.ToTensor()(test_img)\n",
    "    test_img = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(test_img)\n",
    "    test_img = torch.unsqueeze(test_img, 0)\n",
    "    \n",
    "    # set model to use\n",
    "    model = pix2pix(opt)\n",
    "    data = {'A': test_img, 'B': None}\n",
    "    model.set_inputs(data)\n",
    "    \n",
    "    # save output image\n",
    "    model.forward()\n",
    "    B_fake = model.get_B_fake()\n",
    "    Image.fromarray((model.get_B_fake().cpu().numpy() + 1) * 255 / 2 ).convert('RGB')\\\n",
    "                            .save(opt['test_output'])\n",
    "else:\n",
    "    print('It is now in train mode, please check opt.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
